---
title: "Cleaning the cooperatives database"
output:
    html_notebook:
      toc: yes
      toc_depth: 4
      toc_float:
        collapsed: no
---

## Load packages

```{r}
suppressPackageStartupMessages({
  library(magrittr)
  library(tidyverse)
  library(raster)
})
```



## Read in the data

First we will read in all the data from the original csv file, where no changes have been made. We read it in setting `na.strings = 999`, because that is what was used in the creation of the database to report a missing value. We want to convert those to `NA`'s. We will also use `stringAsFactors = F` to make sure that string variables are interpreted as text, not factors. Finally, we include `strip.white = T` to lead any white spaces before or after any words.

```{r}
# Read the data
cooperatives_db <- read.csv("master cooperative database for analysis.csv",
                            na.strings = 999,
                            stringsAsFactors = F,
                            strip.white = T)
# Get a preview
head(cooperatives_db)
```

**You can see that the database has `r dim(cooperatives_db)[1]` rows and `r dim(cooperatives_db)[2]` columns.**

## Standardize column names

We can see that the column names are not standard. Some of them have capital letters, some of them dont. Some include repeated characters, such as `__` instead of just `_`. We want to make sure we fix all these.

First, lets identify all problems:

```{r}
colnames(cooperatives_db)
```

By looking at the column names, there are a few things that we might want to do:

- Convert everything to `snake_case`, where nothing is capitalized and words are separated by a `_`.
- Some values, like column 43 (`Subsidy_as_a___of_landed_value`) have repeated characters, and we want to see `subsidy_as_a_of_landed_values`
- Some values have trailing `_`, like `GDP_from_fishing__US_`, in column 40. We want this to be `gdp_from_fishing_us`
- Government is abbreviated as `gov_t`, like in column 119 (`Gov_t_Ambivalent`). We want this as `gov_ambivalent`
- We see many cases where `cooperative` or `comanagement` are separated by `_` (column 109; `Vessels__co_op_`), and we want `vessels_coop`

We can fix all these with the use of regular expressions and string substitutions:

```{r}
columns <- colnames(cooperatives_db) %>%
  tolower() %>%
  gsub(pattern = "(_)\\1+", replacement = "_") %>% 
  gsub(pattern = "_+$", replacement = "") %>% 
  gsub(pattern = "gov_t", replacement = "gov") %>% 
  gsub(pattern = "co_", replacement = "co") %>% 
  gsub(pattern = "subsidy_as_a_of_landed_value", replacement = "subsidy_as_a_percent_of_landed_value") %>% 
  gsub(pattern = "a_of_gdp_from_fishing", replacement = "percent_of_gdp_from_fishing")

columns
```

Once we like how these look, we just re-name the columns in `cooperatives_db`

```{r}
colnames(cooperatives_db) <- columns

head(cooperatives_db)
```

## Standardize values

Now that the columns look beter, we can go ahead and clean the data itself. First, it would help at identifying all the unique values for each column. In this tree-like viewer, you can click on each of the column names and see a list of all the unique values within it. For example, `entered_by`, which contains information on who entered the data has the unique values `r unique(cooperatives_db$entered_by)`.

```{r}
sort_unique <- function(x){sort(unique(x))}
 
lapply(cooperatives_db, sort_unique) %>% 
  listviewer::jsonedit()
```

By reviewing each of the above, we can identify the following things we might want to fix:

### General fixes

- ~~Make everything sentence case (*i.e.* only first letter of first word capitalized)~~
- Convert values of `(0, 1)` to `(FALSE, TRUE)`

### Column-level fixes

- `entered_by`
    - ~~Contains missing values labeled as `""`, but we want those to be `NA`'s~~
- `umbrella_organization`:
    - ~~Has values of 0, `null` (which are `NA`), 1, and 2.~~
    - ~~These is supposed to be a boolean (*i.e.* `TRUE` / `FALSE`).~~
    - ~~We will set values `umbrella_organization_i > 1` as `TRUE` and `umbrella_organization < 1 as FALSE`~~
- `target_species`:
    - ~~Standardize everything to remove capitalized letters~~
    - Conver all names into english (?)
    - ~~Records 43 (`Callo de hacha (Pen shell)`) and 44 (`Callo de hacha / Pen shell`) are the same species~~
    - There is one missing value. We might be able to fix it based on the scientific name (`complete_name`)
- `complete_name`:
    - Must make sure the names are still valid (?)
    - Missing names (?)
    - ~~Change `Genus sp.` and `Genus spp.` to `Genus spp`~~
    - ~~Delete duplicated white spaces (`Farfantepenaeus  californiensis` to `Farfantepenaeus californiensis`)~~
    - ~~Caribean spiny lobster is lised as `Panulirus argus` and `Panuliris argus`~~
- `fb_migration`:
    - Has values of `r sort(unique(cooperatives_db$fb_migration))`
    - Make sure these are standardized
- `fish_type`:
    - ~~has repeated cases (`Finfish - pelagic` and `Finfish - Pelagic`)~~
- `habitat`:
    - ~~repeated cases (`deep water` and `Deep water`) and other similar captialization issues~~
- `fished_habitat`:
    - ~~repeated cases (`deep water` and `Deep water`) and other similar captialization issues~~
- `species_growth`:
    - ~~Has values of `r sort(unique(cooperatives_db$species_growth))`~~
    - ~~Perhaps `Slow` and `Low` mean the same thing? Review metadata~~
- `adult_movement`
    - ~~Some values are separated by double dashes `--`~~
- `catch_share_types`
    - ~~fix values of `Co-op` to `coop`~~
    - compose a `catch_share_types2` column based on the columns right next to this one
- `species_value` and `unit_of_value`
    - ~~will be fixed by Andrew~~
- `gear_type`
    - ~~misspelled values~~
- `landings_coop` and `landings_units`
    - ~~fixed by Andrew~~
- `use_of_catch`
    - ~~Long record must be shortened (`1.local market (mostly wholesale) 2. subsistence (www.indiana.edu/~voconf/papers/thomson_voconf.pdf)", "local market/subsistance`)~~
    - ~~Replace `;` wih `/`~~
- `vessels_coop`
    - There are some weird records, stating that there are 54010 vessesls for a couple of coops. This might just be datenums that were misshandled. **Check with Dan!**

Most of these problems can be fixed easily by making some small functions:

### Function to transform ONLY CHARACCTER VECTORS to lower

```{r}
ToLower <- function(x){
  classes <- sapply(x, is.character)
  
  cols <- colnames(x)[classes]
  
  mutate_at(x, cols, tolower)
}

```

### Make 1 / 0 columns into T / F

```{r}
makeTF <- function(x){
  lengths <- summarize_all(x, function(x){length(unique(x)) <= 3})
  
  classes <- summarize_all(x, is.numeric)
  
  has10fn <- function(x){
    x[!is.na(x)] %>% 
      unique() %in% 
      c(0, 1) %>% 
      all()}
  
  has10 <- summarize_all(x, has10fn)
  
  conditions <- rbind(lengths, classes, has10) %>% 
    sapply(all)
  
  cols <- colnames(x)[conditions]

  trans_10_TF <- function(x){
    x <- gsub(pattern = "0", replacement = FALSE, x) %>%
      gsub(pattern = "1", replacement = TRUE)
    return(x)
  }

  mutate_at(x, cols, trans_10_TF)
}
```


### Function to remove blank (empty) characters

```{r}
remove_blanks <- function(x){
  classes <- sapply(x, is.character)
  
  cols <- colnames(x)[classes]
  
  mutate_at(x, cols, function(y){gsub(pattern = "^$", replacement = NA, y)})
}
```


### Remove characters with double blanks

```{r}
remove_double_blanks <- function(x){
  classes <- sapply(x, is.character)
  
  cols <- colnames(x)[classes]
  
  mutate_at(x, cols, function(y){gsub(pattern = "( )\\1+", replacement = "\\1", y)})
}
```


### Remove trailing and leading whitespaces

```{r}
remove_spaces <- function(x){
  classes <- sapply(x, is.character)
  
  cols <- colnames(x)[classes]
  
  mutate_at(x, cols, function(y){gsub(pattern = "^\\s+", replacement = "", y)})
}
```


### Remove "blank / blank"
```{r}
remove_bpunctb <- function(x){
  classes <- sapply(x, is.character)
  
  cols <- colnames(x)[classes]
  
  mutate_at(x, cols, function(y){gsub(pattern = "( / )", replacement = "/", y)})
  }
```

### Coerce characters of T and F to logicals

```{r}
makeTF2 <- function(x){
  
  cols <- summarize_all(x, function(y){any(y %in% c("TRUE", "FALSE"))}) %>% 
    gather(variable, value) %>% 
    filter(value) %$% 
    variable
  
  mutate_at(x, cols, as.logical)
}
```



## Make all changes

We can now use the functions above for general fixes, and use `mutate` to fix particular things

```{r}
cooperatives <- ToLower(cooperatives_db) %>% # set to lower case
  makeTF() %>% 
  remove_blanks() %>% #remove blank (empty) cells)
  mutate(umbrella_organization = gsub(pattern = 0, replacement = FALSE, x = umbrella_organization), # Make 0's into FALSE
         umbrella_organization = gsub(pattern = "[1,2]", replacement = TRUE, x = umbrella_organization), # Make xi >= 1 into TRUE
         target_species = gsub(pattern = "[[:punct:]]", replacement = "", x = gsub("\\<callo de hacha\\>", "", target_species)), # Replace duplicated callo
         complete_name = gsub(pattern = "[[:punct:]]", replacement = "", x = gsub(pattern = "sp.", replacement = "spp", complete_name)),
         complete_name = ifelse(complete_name == "panuliris  argus", "panulirus argus", complete_name),
         complete_name = taxize::taxize_capwords(complete_name, strict = T, onlyfirst = T),
         species_growth = ifelse(species_growth == "slow", "low", species_growth),
         adult_movement = gsub(pattern = "--", replacement = "-", adult_movement),
         catch_share_types = gsub(pattern = "-", replacement = "", catch_share_types),
         catch_share_types = gsub(pattern = "coops", replacement = "coop", catch_share_types),
         gear_type = gsub(pattern = "artisianal", replacement = "artisanal", gear_type),
         use_of_catch = ifelse(use_of_catch == "1.local market (mostly wholesale) 2. subsistence (www.indiana.edu/~voconf/papers/thomson_voconf.pdf)", "local market/subsistance", use_of_catch),
         use_of_catch = gsub(pattern = ";", replacement = "/", use_of_catch)) %>%
  remove_double_blanks() %>%
  remove_spaces() %>%
  remove_bpunctb() %>% 
  makeTF2()
```

## Inspection

```{r}
lapply(cooperatives, sort_unique) %>% 
  listviewer::jsonedit()
```

## Adding indicators

Team 1 has extracted values related to Ecological sensitivity, which we can now add to the master database. We can load them and take a look:

```{r}
new_variables <- read.csv("coop_data_habitat.csv", stringsAsFactors = F, strip.white = T)

head(new_variables)
```


The first thing that pops out is the inconsistent column names. Let's fix that first:

```{r}
columns <- colnames(new_variables) %>%
  tolower() %>%
  gsub(pattern = "[[:punct:]]", replacement = "_")

columns
```

These look better, let's update them in the table

```{r}
colnames(new_variables) <- columns

head(new_variables)
```

Let's now inspect unique values:

```{r}
lapply(new_variables, sort_unique) %>% 
  listviewer::jsonedit()
```

There are some inconsistencies, but these can be fixed later.

We can now add these variables to the master db

```{r}
cooperatives %<>%
  left_join(new_variables, by = c("original_order", "fishery_id", "fished_habitat"))
```

## Last Inspection

We can now see the new variables have been added

```{r}
lapply(cooperatives, sort_unique) %>% 
  listviewer::jsonedit()
```


## Add coordinates and Temperature change by `fishery_id`

### Load the coordinates

```{r}
coords <- read.csv("coords.csv", stringsAsFactors = F, strip.white = T) %>% 
  filter(!is.na(lon)) %>% 
  group_by(fishery_id) %>% 
  summarize_at(.vars = c("lat", "lon"), .funs = mean)

cooperatives %<>%
  left_join(coords, by = "fishery_id")
```

### Land shapefile

We will use raster images from [https://cds.nccs.nasa.gov/nex-gddp/](https://cds.nccs.nasa.gov/nex-gddp/). For now, I am using 2006 and 250, and will calculate the difference between these. The raster covers the whole world, but we will only need the ocean. We need a shapefile of land to crop the continents out.

```{r}
proj2 <- "+proj=longlat +datum=WGS84 +ellps=WGS84 +towgs84=0,0,0"

data(World)

World <- as(World, "sf") %>% 
  sf::st_transform(proj2) %>% 
  mutate(N = 1) %>% 
  sf::st_union(by = N) %>% 
  sf::as_Spatial()
```


### Load a raster and mask it by land

We load the rasters, then calculate the difference between them, then rotate them (GCM output is between 0 and 360, we want -180 to 180), and then apply the mask.

```{r}
rasters <- list.files(pattern='tsamax', full.names = T)
r2006 <- stack(rasters[1]) %>% 
  mean() %>% 
  rotate() %>% 
  mask(World, inverse = T)

r2050 <- stack(rasters[2]) %>% 
  mean() %>% 
  rotate() %>% 
  mask(World, inverse = T)

r <- r2050-r2006
```

Let's see how they look

```{r}
plot(r)
```

### Extract values from a raster

Using he coordinates provided for each site, we can extract the temperature differences at avery point, using a buffer. We need to filter-out the freshwater fisheries.

```{r}
saltwater <- cooperatives %>%
  filter(!fish_type == "freshwater") %>% 
  group_by(fishery_id) %>% 
  summarize(lon = mean(lon, na.rm = T), lat = mean(lat, na.rm = T)) %>% 
  filter(!is.na(lon), !is.na(lat))

xy <- data.frame(X = saltwater$lon, Y = saltwater$lat)
coordinates(xy) <- c("X", "Y")
proj4string(xy) <- proj2  ## for example
xy <- SpatialPointsDataFrame(xy, saltwater, proj4string = proj2)

plot(World, col = "gray")
plot(xy, add = T, pch = 20)
```

```{r}
temps <- raster::extract(r, xy, buffer = 50000, fun = mean)
```


### Joit exposure to master DB

```{r}
coords <- cbind(xy, temps) 
colnames(coords@data) <- c("fishery_id", "lon", "lat", "temperature_change")

cooperatives %<>%
  left_join(coords@data, by = c("fishery_id", "lon", "lat")) %>% 
  mutate(temperature_change_normalized = scales::rescale(temperature_change))
```


## Save progress

Everything looks good for now. We can go ahead and save this new version

```{r}
write.csv(x = cooperatives, file = "cooperatives_clean.csv", row.names = F)
save(cooperatives, file = "data/cooperatives.rda")
```








